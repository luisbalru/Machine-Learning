@article{optdigits.names,
	title = "Optical Recognition of Handwritten Digits",
	url = "https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits",
	author = "E. Alpaydin, C. Kaynak",
}

@article{st-sc,
	title ="Standard Scaler en Sklearn",
	url = "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html",
	year = "Consultado el 7 de mayo de 2019",
}

@article{pca,
	author = {Abdi, Hervé and Williams, Lynne J.},
	title = {Principal component analysis},
	journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
	volume = {2},
	number = {4},
	pages = {433-459},
	keywords = {singular and eigen value decomposition, bilinear decomposition, factor scores and loadings, RESS PRESS, multiple factor analysis},
	doi = {10.1002/wics.101},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.101},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.101},
	abstract = {Abstract Principal component analysis (PCA) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the PCA model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. PCA can be generalized as correspondence analysis (CA) in order to handle qualitative variables and as multiple factor analysis (MFA) in order to handle heterogeneous sets of variables. Mathematically, PCA depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (SVD) of rectangular matrices. Copyright © 2010 John Wiley \& Sons, Inc. This article is categorized under: Statistical and Graphical Methods of Data Analysis > Multivariate Analysis Statistical and Graphical Methods of Data Analysis > Dimension Reduction},,
	year = {2010}
}

@article{pca-sk,
	title = "PCA en SKlearn",
	url = "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html",
	year = "Consultado el 7 de mayo de 2019",
}

@article{SGD-C,
	title = "SGD en SKlearn",
	url = "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html",
	year = "Consultado el 8 de mayo de 2019",
}

@article{stk,
	title = "Stratified kfold en SKlearn",
	url = "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html",
	year = "Consultado el 8 de mayo de 2019",
}


@article{smote,
	title = " SMOTE: Synthetic Minority Over-sampling Technique "	
	url = "https://jair.org/index.php/jair/article/view/10302",
	author = "N. V. Chawla, K. W. Bowyer,L. O. Hall,W. P. Kegelmeyer",
}


